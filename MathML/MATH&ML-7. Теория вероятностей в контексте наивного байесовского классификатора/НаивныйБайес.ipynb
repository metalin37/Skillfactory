{"cells":[{"cell_type":"markdown","metadata":{"id":"NlVC5j9gdd99"},"source":["# Наивный Байесовский Классификатор для классификации спам-сообщений"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"i35VBQfFdd-E"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["Прочитаем файл (разделителем здесь выступает символ табуляции)."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"A1b5QrS5dd-F","outputId":"ad0e2dbf-f406-41ae-8cda-9e043efb2f8b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Label                                                SMS\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["sms_data = pd.read_csv('SMSSpamCollection', header=None, sep='\\t', names=['Label', 'SMS'])\n","sms_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Посмотрим, сколько объектов каждого класса присутствует в датасете."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"p7_2JzUvdd-G","outputId":"6167fcf9-f386-48cf-b2fe-4ca8012835c1","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMS</th>\n","    </tr>\n","    <tr>\n","      <th>Label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ham</th>\n","      <td>4825</td>\n","    </tr>\n","    <tr>\n","      <th>spam</th>\n","      <td>747</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        SMS\n","Label      \n","ham    4825\n","spam    747"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["sms_data.groupby('Label').count()"]},{"cell_type":"markdown","metadata":{"id":"hQG2a4SVdd-H"},"source":["### Предобработка данных"]},{"cell_type":"markdown","metadata":{},"source":["Удаляем символы, не являющиеся буквами, приводим тексты SMS к нижнему регистру, разбиваем строки на слова."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"T9c0M4vhdd-I"},"outputs":[],"source":["sms_data_clean = sms_data.copy()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Jd-UcYg6dd-I"},"outputs":[{"data":{"text/plain":["0    [go, until, jurong, point, crazy, available, o...\n","1                       [ok, lar, joking, wif, u, oni]\n","2    [free, entry, in, 2, a, wkly, comp, to, win, f...\n","3    [u, dun, say, so, early, hor, u, c, already, t...\n","4    [nah, i, don, t, think, he, goes, to, usf, he,...\n","Name: SMS, dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["sms_data_clean['SMS'] = sms_data_clean['SMS'].str.replace('\\W+', ' ', regex=True)\n","\n","sms_data_clean['SMS'] = sms_data_clean['SMS'].str.replace('\\s+', ' ', regex=True).str.strip()\n","sms_data_clean['SMS'] = sms_data_clean['SMS'].str.lower()\n","sms_data_clean['SMS'] = sms_data_clean['SMS'].str.split()\n","\n","sms_data_clean['SMS'].head()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PZCmBLCLdd-L","outputId":"e37750a2-4124-4733-9bb2-0e7b057e4171","scrolled":true},"outputs":[{"data":{"text/plain":["ham     86.593683\n","spam    13.406317\n","Name: Label, dtype: float64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["sms_data_clean['Label'].value_counts() / sms_data_clean.shape[0] * 100"]},{"cell_type":"markdown","metadata":{"id":"50oksBrrdd-L"},"source":["### Разделение на обучающую и тестовую выборки"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["train_data = sms_data_clean.sample(frac=0.8, random_state=42)\n","test_data = sms_data_clean.drop(train_data.index)\n","\n","train_data = train_data.reset_index(drop=True)\n","test_data = test_data.reset_index(drop=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"WU_YwDxgdd-M","outputId":"d7897ce6-95c9-4be3-f269-5009666c7f3e"},"outputs":[{"data":{"text/plain":["ham     86.698071\n","spam    13.301929\n","Name: Label, dtype: float64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_data['Label'].value_counts() / train_data.shape[0] * 100"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"B_WG0yuqdd-M","outputId":"c3c9a44e-9ee8-42f4-d6b6-5522898cb267"},"outputs":[{"data":{"text/plain":["(4458, 2)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_data.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fbrlnUxfdd-N","outputId":"2bdc65d7-0b76-4c28-dae7-d1fe620e6a59"},"outputs":[{"data":{"text/plain":["ham     86.175943\n","spam    13.824057\n","Name: Label, dtype: float64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test_data['Label'].value_counts() / test_data.shape[0] * 100"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dHM1P3h2dd-N","outputId":"4b2a0eba-0468-4e7d-e1dd-f091728cdecc","scrolled":true},"outputs":[{"data":{"text/plain":["(1114, 2)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["test_data.shape"]},{"cell_type":"markdown","metadata":{},"source":["Мы видим, что и в обучающей, и в тестовой выборке содержится примерно 86-87% спама – как и в нашем оригинальном датасете."]},{"cell_type":"markdown","metadata":{"id":"CVmTrhNSdd-O"},"source":["### Список слов"]},{"cell_type":"markdown","metadata":{},"source":["Создаём список всех слов, встречающихся в обучающей выборке."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ahLFpWI3dd-O"},"outputs":[],"source":["vocabulary = list(set(train_data['SMS'].sum()))"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"eSN6U0QLdd-O","outputId":"5dcb7d6f-900f-483c-e896-4ef69459dced"},"outputs":[{"data":{"text/plain":["['recreation',\n"," 'wan2',\n"," 'kickboxing',\n"," 'establish',\n"," 'tonexs',\n"," 'aha',\n"," 'lov',\n"," 'lifetime',\n"," 'jorge']"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["vocabulary[11:20]"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"MegzBwCFdd-P","outputId":"fa6a956c-5602-4193-8925-6ecb43b5b719"},"outputs":[{"data":{"text/plain":["7816"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(vocabulary)"]},{"cell_type":"markdown","metadata":{"id":"xs_mok2wdd-P"},"source":["### Рассчитаем частоты слов"]},{"cell_type":"markdown","metadata":{},"source":["Для каждого SMS-сообщения посчитаем, сколько раз в нём встречается каждое слово."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"vER-xPhXdd-P"},"outputs":[],"source":["word_counts_per_sms = pd.DataFrame([\n","    [row[1].count(word) for word in vocabulary]\n","    for _, row in train_data.iterrows()], columns=vocabulary)\n","\n","word_counts_per_sms.head()"]},{"cell_type":"markdown","metadata":{},"source":["Добавим частоты каждого слова в обучающий датасет."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"dNc8Juygdd-P"},"outputs":[],"source":["train_data = pd.concat([train_data, word_counts_per_sms], axis=1)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"FxcXHWgqdd-Q","outputId":"cda89d7c-4596-4dc7-e274-01afb214c54c","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","      <th>ym</th>\n","      <th>anand</th>\n","      <th>percent</th>\n","      <th>89034</th>\n","      <th>one</th>\n","      <th>ip</th>\n","      <th>junna</th>\n","      <th>bcm</th>\n","      <th>...</th>\n","      <th>542</th>\n","      <th>onum</th>\n","      <th>aberdeen</th>\n","      <th>3d</th>\n","      <th>stereo</th>\n","      <th>anal</th>\n","      <th>election</th>\n","      <th>smiles</th>\n","      <th>postcode</th>\n","      <th>cooked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>[squeeeeeze, this, is, christmas, hug, if, u, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>[and, also, i, ve, sorta, blown, him, off, a, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ham</td>\n","      <td>[mmm, thats, better, now, i, got, a, roast, do...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>[mm, have, some, kanji, dont, eat, anything, h...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>[so, there, s, a, ring, that, comes, with, the...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 7818 columns</p>\n","</div>"],"text/plain":["  Label                                                SMS  ym  anand  \\\n","0   ham  [squeeeeeze, this, is, christmas, hug, if, u, ...   0      0   \n","1   ham  [and, also, i, ve, sorta, blown, him, off, a, ...   0      0   \n","2   ham  [mmm, thats, better, now, i, got, a, roast, do...   0      0   \n","3   ham  [mm, have, some, kanji, dont, eat, anything, h...   0      0   \n","4   ham  [so, there, s, a, ring, that, comes, with, the...   0      0   \n","\n","   percent  89034  one  ip  junna  bcm  ...  542  onum  aberdeen  3d  stereo  \\\n","0        0      0    0   0      0    0  ...    0     0         0   0       0   \n","1        0      0    0   0      0    0  ...    0     0         0   0       0   \n","2        0      0    0   0      0    0  ...    0     0         0   0       0   \n","3        0      0    0   0      0    0  ...    0     0         0   0       0   \n","4        0      0    0   0      0    0  ...    0     0         0   0       0   \n","\n","   anal  election  smiles  postcode  cooked  \n","0     0         0       0         0       0  \n","1     0         0       0         0       0  \n","2     0         0       0         0       0  \n","3     0         0       0         0       0  \n","4     0         0       0         0       0  \n","\n","[5 rows x 7818 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"markdown","metadata":{"id":"On-SEF1fdd-Q"},"source":["### Значения для формулы Байеса"]},{"cell_type":"markdown","metadata":{},"source":["Посчитаем необходимые значения для формулы Байеса."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"IwxBHjXYdd-Q"},"outputs":[],"source":["alpha = 1"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"gxsFfXOzdd-Q"},"outputs":[],"source":["Nvoc = len(vocabulary)\n","Pspam = train_data['Label'].value_counts()['spam'] / train_data.shape[0]\n","Pham = train_data['Label'].value_counts()['ham'] / train_data.shape[0]\n","Nspam = train_data.loc[train_data['Label'] == 'spam', 'SMS'].apply(len).sum()\n","Nham = train_data.loc[train_data['Label'] == 'ham', 'SMS'].apply(len).sum()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"jde0BGdPdd-R"},"outputs":[],"source":["def p_w_spam(word):\n","    if word in train_data.columns:\n","        return (train_data.loc[train_data['Label'] == 'spam', word].sum() + alpha) / (Nspam + alpha*Nvoc)\n","    else:\n","        return 1\n","\n","def p_w_ham(word):\n","    if word in train_data.columns:\n","        return (train_data.loc[train_data['Label'] == 'ham', word].sum() + alpha) / (Nham + alpha*Nvoc)\n","    else:\n","        return 1"]},{"cell_type":"markdown","metadata":{"id":"u-nPavNOdd-S"},"source":["### Готовим алгоритм классификации"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Ib39OrM8dd-S"},"outputs":[],"source":["def classify(message):\n","    p_spam_given_message = Pspam\n","    p_ham_given_message = Pham\n","    for word in message:\n","        p_spam_given_message *= p_w_spam(word)\n","        p_ham_given_message *= p_w_ham(word)\n","    if p_ham_given_message > p_spam_given_message:\n","        return 'ham'\n","    elif p_ham_given_message < p_spam_given_message:\n","        return 'spam'\n","    else:\n","        return 'классификация некорректна'"]},{"cell_type":"markdown","metadata":{"id":"7QECGrw8dd-S"},"source":["### Используем тестовые данные"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"dNWXV-5odd-S"},"outputs":[],"source":["test_data['predicted'] = test_data['SMS'].map(classify)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"AejY85XOdd-S","outputId":"112fe436-4d36-42a6-8d3d-8952e282939c","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>[freemsg, hey, there, darling, it, s, been, 3,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>spam</td>\n","      <td>[had, your, mobile, 11, months, or, more, u, r...</td>\n","      <td>spam</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>[oh, k, i, m, watching, here]</td>\n","      <td>ham</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Label                                                SMS predicted\n","0   ham  [u, dun, say, so, early, hor, u, c, already, t...       ham\n","1   ham  [nah, i, don, t, think, he, goes, to, usf, he,...       ham\n","2  spam  [freemsg, hey, there, darling, it, s, been, 3,...       ham\n","3  spam  [had, your, mobile, 11, months, or, more, u, r...      spam\n","4   ham                      [oh, k, i, m, watching, here]       ham"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head()"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"lNHidizgdd-T"},"outputs":[{"name":"stdout","output_type":"stream","text":["Правильных предсказаний 98.025135 %\n"]}],"source":["correct = (test_data['predicted'] == test_data['Label']).sum() / test_data.shape[0]\n","print(f\"Правильных предсказаний {correct * 100:3f} %\")"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"-s5NRlJGdd-T","outputId":"de7985cf-9878-486c-ff7a-54295961199e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>[freemsg, hey, there, darling, it, s, been, 3,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>ham</td>\n","      <td>[waiting, for, your, call]</td>\n","      <td>spam</td>\n","    </tr>\n","    <tr>\n","      <th>182</th>\n","      <td>ham</td>\n","      <td>[26th, of, july]</td>\n","      <td>spam</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>spam</td>\n","      <td>[sms, ac, jsco, energy, is, high, but, u, may,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>ham</td>\n","      <td>[the, last, thing, i, ever, wanted, to, do, wa...</td>\n","      <td>классификация некорректна</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Label                                                SMS  \\\n","2    spam  [freemsg, hey, there, darling, it, s, been, 3,...   \n","96    ham                         [waiting, for, your, call]   \n","182   ham                                   [26th, of, july]   \n","269  spam  [sms, ac, jsco, energy, is, high, but, u, may,...   \n","344   ham  [the, last, thing, i, ever, wanted, to, do, wa...   \n","\n","                     predicted  \n","2                          ham  \n","96                        spam  \n","182                       spam  \n","269                        ham  \n","344  классификация некорректна  "]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["test_data.loc[test_data['predicted'] != test_data['Label']].head()"]},{"cell_type":"markdown","metadata":{},"source":["# Наивный байесовский классификатор в sklearn\n","Ура, мы реализовали наивный байесовский классификатор с нуля!\n","А теперь посмотрим, как то же самое можно сделать с помощью библиотеки scikit-learn."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"V3xAvBRndd-T"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB"]},{"cell_type":"markdown","metadata":{},"source":["Прочитаем заново csv-файл и предобработаем данные. Разбивать сообщения на слова в этот раз не нужно, мы сделаем это далее с помощью встроенных инструментов"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go until jurong point crazy available only in ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar joking wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say so early hor u c already then say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah i don t think he goes to usf he lives arou...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Label                                                SMS\n","0   ham  go until jurong point crazy available only in ...\n","1   ham                            ok lar joking wif u oni\n","2  spam  free entry in 2 a wkly comp to win fa cup fina...\n","3   ham        u dun say so early hor u c already then say\n","4   ham  nah i don t think he goes to usf he lives arou..."]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\n","    \"SMSSpamCollection.csv\", header=None, sep=\"\\t\", names=[\"Label\", \"SMS\"]\n",")\n","\n","df[\"SMS\"] = df[\"SMS\"].str.replace(r\"\\W+\", \" \", regex=True).str.lower()\n","\n","df['SMS'] = df['SMS'].str.replace('\\s+', ' ', regex=True).str.strip()\n","df['SMS'] = df['SMS'].str.lower()\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Преобразуем строки в векторный вид – то есть, снова создадим таблицу с частотами слов. Но в этот раз воспользуемся встроенным в sklearn классов CountVectorizer()."]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(5572, 8713) (5572,)\n"]}],"source":["vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(df[\"SMS\"])\n","y = df[\"Label\"]\n","\n","print(X.shape, y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["С помощью функции `train_test_split` из scikit-learn разобьём выборку на обучающую и тестовую в пропорции 80/20. Не забудем сделать стратификацию!"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.979372197309417\n"]}],"source":["clf = MultinomialNB()\n","clf.fit(X_train, y_train)\n","\n","y_test_pred = clf.predict(X_test)\n","\n","print(f\"Accuracy: {accuracy_score(y_test, y_test_pred)}\")"]}],"metadata":{"colab":{"name":"НаивныйБайес.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"86c56a74836ad344b00594bf6f38fa6a676a207ceefe20d101fbc465800ccb8d"}}},"nbformat":4,"nbformat_minor":0}
